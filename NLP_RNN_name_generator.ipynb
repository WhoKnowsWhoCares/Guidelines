{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"NLP_RNN_name_generator.ipynb","provenance":[{"file_id":"https://github.com/Samsung-IT-Academy/stepik-dl-nlp/blob/master/task4_RNN_name_generator.ipynb","timestamp":1625152640096}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"LPveouPIkayu"},"source":["# Генерация текста с помощью RNN\n"]},{"cell_type":"markdown","metadata":{"id":"_x92u4ilkayx"},"source":["(по мотивам [семинара](https://github.com/neychev/harbour_dlia2019/blob/master/day02_Simple_RNN/Day_2_Simple_RNN_pytorch.ipynb)\n"," [курса \"Deep Learning in Applications\"](https://in.harbour.space/data-science/deep-learning-in-applications-radoslav-neychev-anastasia-ianina/))"]},{"cell_type":"code","metadata":{"id":"fNpCkKBKkayx"},"source":["# Если Вы запускаете ноутбук на colab или kaggle,\n","# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n","\n","# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n","# import sys; sys.path.append('./stepik-dl-nlp')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:20:34.854793Z","start_time":"2019-11-05T18:20:34.372865Z"},"id":"LoGlFnjjkayy"},"source":["import os\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8CqZNV_vkayy"},"source":["# Данные\n","Датасет содержит ~9k имен, все написаны латиницей."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:03.509714Z","start_time":"2019-11-05T18:21:03.491489Z"},"id":"HuQVDPMgkayz"},"source":["# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n","with open('datasets/russian_names.txt') as input_file:\n","    names = input_file.read()[:-1].split('\\n')\n","    names = [' ' + line for line in names]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:03.946758Z","start_time":"2019-11-05T18:21:03.938432Z"},"id":"JUDFBZBCkayz"},"source":["names[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XFqR2mMGkay1"},"source":["Посмотрим на распределение длин имен:"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:05.420060Z","start_time":"2019-11-05T18:21:05.179513Z"},"id":"5II4l92Skay1"},"source":["plt.title('Name length distribution')\n","plt.hist(list(map(len, names)), bins=25);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"knCS61fMkay2"},"source":["# Препроцессинг"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:07.335188Z","start_time":"2019-11-05T18:21:07.320148Z"},"id":"TsI6ZwVrkay2"},"source":["#all unique characters go here\n","tokens = list(set(''.join(names)))\n","\n","num_tokens = len(tokens)\n","print ('num_tokens = ', num_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-iBoOkQlkay2"},"source":["### Символы -> id\n","\n","Создадим словарь < символ > -> < id >"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:07.674548Z","start_time":"2019-11-05T18:21:07.671129Z"},"id":"wXe2xHBHkay3"},"source":["token_to_id = {token: idx for idx, token in enumerate(tokens)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:07.838814Z","start_time":"2019-11-05T18:21:07.833611Z"},"id":"uvJtl9rHkay3"},"source":["assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n","\n","for i in range(num_tokens):\n","    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n","\n","print(\"Seems alright!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:07.988093Z","start_time":"2019-11-05T18:21:07.977722Z"},"id":"Xst8OnFzkay3"},"source":["def to_matrix(data, token_to_id, max_len=None, dtype='int32', batch_first = True):\n","    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n","    \n","    max_len = max_len or max(map(len, data))\n","    data_ix = np.zeros([len(data), max_len], dtype) + token_to_id[' ']\n","\n","    for i in range(len(data)):\n","        line_ix = [token_to_id[c] for c in data[i]]\n","        data_ix[i, :len(line_ix)] = line_ix\n","        \n","    if not batch_first: # convert [batch, time] into [time, batch]\n","        data_ix = np.transpose(data_ix)\n","\n","    return data_ix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:08.136936Z","start_time":"2019-11-05T18:21:08.131609Z"},"id":"TGHLe7hUkay3"},"source":["#Example: cast 4 names to matrices, pad with zeros\n","print('\\n'.join(names[::2000]))\n","print(to_matrix(names[::2000], token_to_id))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H7Z_AQ6dkay4"},"source":["# Рекуррентные нейронные сети\n","\n","<img src=\"https://github.com/Samsung-IT-Academy/stepik-dl-nlp/blob/master/img/rnn.png?raw=1\" width=480>"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:10.739438Z","start_time":"2019-11-05T18:21:09.661222Z"},"id":"tl-gmtbhkay4"},"source":["import torch, torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"Qn4fmOi2kay7"},"source":["### Более простое решение\n","\n","* `nn.RNNCell(emb_size, rnn_num_units)` - шаг RNN. Алгоритм: concat-linear-tanh\n","* `nn.RNN(emb_size, rnn_num_units` - весь rnn_loop.\n","\n","Кроме того, в PyTorch есть `nn.LSTMCell`, `nn.LSTM`, `nn.GRUCell`, `nn.GRU`, etc. etc.\n","\n","Перепишем наш пример с генерацией имен с помощью средств PyTorch."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.713285Z","start_time":"2019-11-05T18:21:23.704755Z"},"id":"vP2W0Uujkay7"},"source":["class CharRNNLoop(nn.Module):\n","    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n","        super(self.__class__, self).__init__()\n","        self.emb = nn.Embedding(num_tokens, emb_size)\n","        self.rnn = nn.RNN(emb_size, rnn_num_units, batch_first=True)\n","        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n","        \n","    def forward(self, x):\n","        assert isinstance(x, Variable) and isinstance(x.data, torch.LongTensor)\n","        h_seq, _ = self.rnn(self.emb(x))\n","        next_logits = self.hid_to_logits(h_seq)\n","        next_logp = F.log_softmax(next_logits, dim=-1)\n","        return next_logp\n","    \n","model = CharRNNLoop()\n","opt = torch.optim.Adam(model.parameters())\n","history = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:23.790047Z","start_time":"2019-11-05T18:21:23.715167Z"},"id":"IlDhu3Zdkay8"},"source":["# the model applies over the whole sequence\n","batch_ix = to_matrix(sample(names, 32), token_to_id, max_len=MAX_LENGTH)\n","batch_ix = Variable(torch.LongTensor(batch_ix))\n","\n","logp_seq = model(batch_ix)\n","\n","# compute loss\n","loss = F.nll_loss(logp_seq[:, 1:].contiguous().view(-1, num_tokens), \n","                  batch_ix[:, :-1].contiguous().view(-1))\n","\n","loss.backward()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.468107Z","start_time":"2019-11-05T18:21:23.792092Z"},"id":"VUrqs1QYkay8"},"source":["MAX_LENGTH = max(map(len, names))\n","\n","for i in range(1000):\n","    batch_ix = to_matrix(sample(names, 32), token_to_id, max_len=MAX_LENGTH)\n","    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n","    \n","    logp_seq = model(batch_ix)\n","    \n","    # compute loss\n","    predictions_logp = logp_seq[:, :-1]\n","    actual_next_tokens = batch_ix[:, 1:]\n","\n","    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None]))\n","    \n","    # train with backprop\n","    loss.backward()\n","    opt.step()\n","    opt.zero_grad()\n","    \n","    history.append(loss.data.numpy())\n","    if (i + 1) % 100 == 0:\n","        clear_output(True)\n","        plt.plot(history, label='loss')\n","        plt.legend()\n","        plt.show()\n","\n","assert np.mean(history[:25]) > np.mean(history[-25:]), \"RNN didn't converge.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-05T18:21:31.526436Z","start_time":"2019-11-05T18:21:31.469965Z"},"id":"Sl5mUNhpkay8"},"source":["for _ in range(10):\n","    print(generate_sample(char_rnn))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4S3JgPkkay_"},"source":[""],"execution_count":null,"outputs":[]}]}