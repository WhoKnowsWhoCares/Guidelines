{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8F28mYbZJUo"
      },
      "source": [
        "*(to use GPU in colab go to Runtime -> Change Runtime Type and change the hardware accelerator)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUQ4miJsADfn"
      },
      "source": [
        "Только вчера закончился долгожданный посвят, но времени на отдых нет — до дедлайна по Variational Autoencoders всего 4 часа! Вы открываете ноутбук, готовясь внести последние штрихи, но с ужасом понимаете: задание в хаосе. Часть кода исчезла, а оставшиеся строки пестрят ошибками. В каком же состоянии Вы были, когда работали над этим вчера? Время неумолимо бежит, и теперь нужно срочно все исправить и успеть обучить модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x_Dd0j4pcw9-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alexander/Documents/Programming/Guidelines/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using torch version 2.1.2+cu121\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "# some prelimenaries\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "torch.set_num_threads(16)\n",
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "print('Using torch version {}'.format(torch.__version__))\n",
        "print('Using {} device'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wigquq3OADfo"
      },
      "source": [
        "Эти составители задания явно не желали облегчить Вам жизнь! Подсунули сломанный MNIST, нужно возиться с размерностью. И как будто этого недостаточно, ведь для восстановления её нельзя пользоваться любыми вспомогательными функциями из PyTorch и NumPy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B_sVBI_2x-RS"
      },
      "outputs": [],
      "source": [
        "def transpose_from_scratch(lst):\n",
        "    \"\"\"\n",
        "    Меняет местами две оси (размерности) вложенного списка и возвращает результат в виде torch.Tensor.\n",
        "\n",
        "    Parameters:\n",
        "    lst: Входной многомерный вложенный список или torch.Tensor\n",
        "    Returns:\n",
        "    torch.Tensor: Новый тензор с переставленными осями\n",
        "    \"\"\"\n",
        "    res = []\n",
        "    for i in range(len(lst[0])):\n",
        "        res.append([])\n",
        "        for j in range(len(lst)):\n",
        "            res[i].append(lst[j][i])\n",
        "    return torch.tensor(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7laPQ52jADfo"
      },
      "source": [
        "Фух, ну и пришлось повозиться. Теперь осталось только настроить загрузчики тренировочных и тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "r5tFoBLdx-RT"
      },
      "outputs": [],
      "source": [
        "train_loader =  DataLoader('./data/transposed_mnist_train.pt')\n",
        "test_loader = DataLoader('./data/transposed_mnist_test.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6YjhnVjADfo"
      },
      "source": [
        "# Вариационные автоэнкодеры\n",
        "\n",
        "Ну вот, Вы наконец добрались до самой важной части. Теперь нужно разобраться с реализацией VAE на MNIST и поправить все косяки, которые Вы наделали вчера, чтобы обучение прошло нормально и тестовый loss был в порядке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCGwVlZWdUA-"
      },
      "source": [
        "# Распределения для вариационных автоэнкодеров\n",
        "\n",
        "Воспоминания со вчерашнего дня возвращаются медленно, поэтому освежим необходимые для выполнения задания основы. Вам понадобятся два типа распределений для вероятностной модели:\n",
        "- **Для z**: используйте вектор независимых [нормально распределённых](https://pytorch.org/docs/stable/distributions.html#normal)  величин.\n",
        "- **Для x**: используйте вектор независимых случайных величин с распределением [Бернулли](https://pytorch.org/docs/stable/distributions.html#bernoulli).\n",
        "\n",
        "По умолчанию, соответствующие классы в PyTorch моделируют тензор независимых случайных величин. Чтобы представить матрицу таких величин как батч случайных векторов, можно использовать класс [Independent](https://pytorch.org/docs/stable/distributions.html#independent).\n",
        "\n",
        "### Распределение Бернулли\n",
        "\n",
        "Лучше инициализировать класс Бернулли **логитами**, а не вероятностями. Это помогает избежать нестабильности при вычислении логарифма вероятности.\n",
        "\n",
        "В этом задании Вам будет нужно использовать этот класс для моделирования $p(x \\mid z)$, параметризованного выходом декодера. Для вычисления функции потерь вам нужно будет использовать метод *log_prob()* для вычисления $\\log p(x \\mid z)$ на входных изображениях.\n",
        "\n",
        "### Нормальное распределение\n",
        "\n",
        "Вы будете использовать этот класс для определения распределения $q(z \\mid x)$ и распределения скрытой переменной $p(z)$.\n",
        "- Для функции потерь используйте метод *log_prob()*.\n",
        "- Чтобы сгенерировать выборку из $q(z \\mid x)$, которую затем можно передать в декодер, используйте метод сэмплирования, реализующий трюк репараметризации. При этом выборка вычисляется как $z = \\mu(x) + \\varepsilon \\odot \\sigma(x)$, где $\\varepsilon$ — стандартный гауссов шум.\n",
        "\n",
        "Здесь $\\odot$ обозначает поэлементное умножение.\n",
        "\n",
        "Следует отметить, что метод сэмплирования (rsample), реализующий [трюк репараметризации](https://runebook.dev/en/articles/pytorch/distributions/torch.distributions.half_normal.HalfNormal.has_rsample), отличается от стандартного метода выборки и специально предназначен для корректного учета градиентов, что особенно важно при обучении моделей, таких как вариационные автоэнкодеры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9r_hPaHx0Jz1"
      },
      "outputs": [],
      "source": [
        "from torch.distributions import Normal, Bernoulli, Independent, constraints\n",
        "Bernoulli.support = constraints.interval(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wtFSf25dXjx"
      },
      "source": [
        "# Вариационные автоэнкодеры\n",
        "\n",
        "Вариационный автоэнкодер состоит из двух основных компонентов. Первая компонента - вероятностная модель для наблюдений:\n",
        "\\begin{align}\n",
        "& p(x, z \\mid \\theta) =  p(z) p(x \\mid z, \\theta) \\\\\n",
        "& p(z) = \\mathcal N(z \\mid 0, I) \\\\\n",
        "& p(x \\mid z, \\theta) = \\prod_{i = 1}^D p_i(z, \\theta)^{x_i} (1 - p_i(z, \\theta))^{1 - x_i}.\n",
        "\\end{align}\n",
        "\n",
        "Здесь $p(z)$ - нормальное распределение со средним $0$ и единичной ковариацией, а $p(x \\mid z, \\theta)$ моделируется как произведение распределений Бернулли для каждого элемента данных.\n",
        "\n",
        "Вторая компонента - вариационное приближение, которое используется для вычисления нижней границы на маргинальное правдоподобие (вариационные автоэнкодеры используют отрицательную нижнюю границу в качестве функции потерь)\n",
        "\\begin{equation}\n",
        "q(z \\mid x, \\phi) = \\mathcal N(z \\mid \\mu(x, \\phi), \\operatorname{diag}(\\sigma^2(x, \\phi))).\n",
        "\\end{equation}\n",
        "\n",
        "Нижняя граница для вероятности наблюдения $x$ из мини-батча выражается как:\n",
        "$$ \\mathcal L(x, \\theta, \\phi) = \\mathbb E_{q(z \\mid x, \\phi)} \\left[ \\log p(x \\mid z, \\phi) + \\log p(z) - \\log q(z \\mid x, \\theta) \\right] $$\n",
        "\n",
        "Однако вычислить это математическое ожидания напрямую сложно. Стандартный подход - аппроксимировать его с помощью оценки Монте-Карло с одним сэмплом:\n",
        "\\begin{align*}\n",
        "\\log p(x \\mid z_0, \\phi) + \\log p(z_0) - \\log q(z_0 \\mid x, \\theta) \\\\\n",
        "z_0 = \\mu(x, \\phi) + \\sigma^2(x, \\phi)^T \\varepsilon_0 \\\\\n",
        "\\varepsilon_0 \\sim \\mathcal N(0, I)\n",
        "\\end{align*}\n",
        "\n",
        "Для обучения модели мы усредняем значения нижней границы по мини-батчу и затем максимизируем это среднее с помощью градинтного подъема:\n",
        "$$ \\frac{1}{N} \\sum_{n=1}^N \\log p(x_n \\mid z_n, \\phi) + \\log p(z_n) - \\log q(z_n \\mid x_n, \\theta) \\rightarrow \\max_{\\theta, \\phi} $$\n",
        "\n",
        "## Энкодер и декодер\n",
        "\n",
        "Распределение $q(z\\mid x, \\theta)$ называется **энкодером**, так как оно кодирует данные $x$ в латентное представление $z$. Распределение $p(x\\mid z, \\phi)$ называется **декодером**, поскольку оно декодируем латентное представление обратно в данные $x$.\n",
        "\n",
        "Для параметризации этих распределений используются для нейронные сети:\n",
        "- **enc** принимает на вход $x$ и возвращает вектор размерности $2\\times d$, который задаёт среднее $\\mu(x, \\phi)$ и стандартное отклонение $\\sigma(x, \\phi)$ для распределения $q(z\\mid x,\\theta)$.\n",
        "- **dec** принимает на вход латентное представление $z$ и возвращает логиты для распределения $p(x\\mid z,\\phi)$.\n",
        "\n",
        "Структура вычислительного графа вариационного автоэнкодера похожа на обычный автоэнкодер, но с добавлением стохастической переменной $\\varepsilon$:\n",
        "\n",
        "![vae](https://github.com/Berdash/CV_notebook/blob/main/vae.png?raw=true)\n",
        "\n",
        "К сожалению, даже если архитектура когда была в задании, вы ее успели удалить, чтобы написать свою.\n",
        "\n",
        "**Ожидается**, что:\n",
        "Вы не будете менять размерности на входе, выходе и на скрытом слое, а также будете в своей реализации четко следовать тексту ниже\n",
        "\n",
        "**Энкодер** будет принимать на вход изображение, развернутое в вектор длины D = 28 * 28, и преобразовывать его в латентное представление.\n",
        "Архитектура должна включать всего три линейных слоя (один входной, один выходной и один скрытый), nn.Linear и две функции активации nn.ReLU.\n",
        "Последний слой должен возвращать вектор размерности 2 * d, где d — размерность латентного пространства. Этот вектор будет использоваться для вычисления среднего и стандартного отклонения в репараметризации.\n",
        "\n",
        "**Декодер** будет принимать на вход латентное представление размерности d и восстанавливать его в изображение размерности D.\n",
        "Декодер должен опять же включать всего три линейных слоя (один входной, один выходной и один скрытый), nn.Linear и две функции активации nn.ReLU.\n",
        "Последний слой должен возвращать вектор размерности D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XnxFqNpbbIZs"
      },
      "outputs": [],
      "source": [
        "d, nh, D = 32, 200, 28 * 28\n",
        "\n",
        "enc = nn.Sequential(\n",
        "    nn.Linear(in_features=D, out_features=nh),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=nh, out_features=2*d)\n",
        "    )\n",
        "\n",
        "dec = nn.Sequential(\n",
        "    nn.Linear(in_features=d, out_features=nh),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=nh, out_features=D)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xqmyAtbfmhG"
      },
      "source": [
        "## Функция потерь вариационного автоэнкодера\n",
        "\n",
        "Вот мы и добрались до того самого места, где ваши руки вчера особенно порезвились! Здесь явно спрятались три ошибки — сумеете их отыскать? Подсказка: теория может стать вашим лучшим другом в этом поиске!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ymwPo9E3erVB"
      },
      "outputs": [],
      "source": [
        "def loss_vae(x, encoder, decoder):\n",
        "    \"\"\"\n",
        "    returns\n",
        "    1. the avergave value of negative ELBO across the minibatch x\n",
        "    2. and the output of the decoder\n",
        "    \"\"\"\n",
        "    batch_size = x.size(0)\n",
        "    encoder_output = encoder(x)\n",
        "    pz = Independent(Normal(loc=torch.zeros(batch_size, d).to(device),\n",
        "                            scale=torch.ones(batch_size, d).to(device)),\n",
        "                     reinterpreted_batch_ndims=1)\n",
        "    qz_x = Independent(Normal(loc=encoder_output[:, :d],\n",
        "                              scale=torch.exp(encoder_output[:, :d])),\n",
        "                       reinterpreted_batch_ndims=1)\n",
        "    z = qz_x.sample()\n",
        "\n",
        "    decoder_output = decoder(z)\n",
        "    px_z = Independent(Bernoulli(logits=decoder_output),\n",
        "                       reinterpreted_batch_ndims=1)\n",
        "\n",
        "    loss = -(px_z.log_prob(x) + pz.log_prob(z) + qz_x.log_prob(z)).mean()\n",
        "    return loss, decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U-7zR3JRO4jC"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'data'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Пример данных: Перемещаем данные на устройство\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m x_sample \u001b[38;5;241m=\u001b[39m \u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m      5\u001b[0m x_sample \u001b[38;5;241m=\u001b[39m x_sample\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, D)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Отправляем модели на нужное устройство\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'data'"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Пример данных: Перемещаем данные на устройство\n",
        "x_sample = test_loader.dataset.data[0].float().unsqueeze(0).to(device) / 255.0\n",
        "x_sample = x_sample.view(-1, D).to(device)\n",
        "\n",
        "# Отправляем модели на нужное устройство\n",
        "enc = enc.to(device)\n",
        "dec = dec.to(device)\n",
        "with torch.no_grad():\n",
        "    loss_value, _ = loss_vae(x_sample, enc, dec)\n",
        "\n",
        "print(f\"Loss: {loss_value.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIMpMloYfyJT"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLI_soZRfzBM"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "\n",
        "def train_model(loss, model, batch_size=100, num_epochs=3, learning_rate=1e-3):\n",
        "    gd = torch.optim.Adam(\n",
        "        chain(*[x.parameters() for x in model\n",
        "                if (isinstance(x, nn.Module) or isinstance(x, nn.Parameter))]),\n",
        "        lr=learning_rate)\n",
        "    train_losses = []\n",
        "    test_results = []\n",
        "    for _ in range(num_epochs):\n",
        "        for i, (batch, _) in enumerate(train_loader):\n",
        "            total = len(train_loader)\n",
        "            gd.zero_grad()\n",
        "            batch = batch.view(-1, D).to(device)\n",
        "            loss_value, _ = loss(batch, *model)\n",
        "            loss_value.backward()\n",
        "            train_losses.append(loss_value.item())\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print('\\rTrain loss:', train_losses[-1],\n",
        "                      'Batch', i + 1, 'of', total, ' ' * 10, end='', flush=True)\n",
        "            gd.step()\n",
        "        test_loss = 0.\n",
        "        for i, (batch, _) in enumerate(test_loader):\n",
        "            batch = batch.view(-1, D).to(device)\n",
        "            batch_loss, _ = loss(batch, *model)\n",
        "            test_loss += (batch_loss - test_loss) / (i + 1)\n",
        "        print('\\nTest loss after an epoch: {}'.format(test_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBdmTPTax-RV"
      },
      "source": [
        "Правильная реализация должна выдавать тестовый лосс где-то в районе 104.\n",
        "\n",
        "А вот 120+ — это уже совсем не то, что нам надо, так что не расслабляемся! Удачи!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPjL_TOpf17s"
      },
      "outputs": [],
      "source": [
        "train_model(loss_vae, model=[enc, dec], num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McWlphgdf5ip"
      },
      "source": [
        "## Visualisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXg47-euADfr"
      },
      "source": [
        "Вы уже на финишной прямой! Давайте взглянем, какие картинки у нас генерируются, и можно продолжать праздновать посвят!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgFFrXPxkNAh"
      },
      "outputs": [],
      "source": [
        "def sample_vae(dec, n_samples=50):\n",
        "    with torch.no_grad():\n",
        "        samples = torch.sigmoid(dec(torch.randn(n_samples, d).to(device)))\n",
        "        samples = samples.view(n_samples, 28, 28).cpu().numpy()\n",
        "    return samples\n",
        "\n",
        "def plot_samples(samples, h=5, w=10):\n",
        "    fig, axes = plt.subplots(nrows=h,\n",
        "                             ncols=w,\n",
        "                             figsize=(int(1.4 * w), int(1.4 * h)),\n",
        "                             subplot_kw={'xticks': [], 'yticks': []})\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.imshow(samples[i], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jX7z79vpAUp1"
      },
      "outputs": [],
      "source": [
        "plot_samples(sample_vae(dec=dec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVfp4hfbf66d"
      },
      "outputs": [],
      "source": [
        "def plot_reconstructions(loss, model):\n",
        "    with torch.no_grad():\n",
        "        batch = (test_loader.dataset.data[:25].float() / 255.)\n",
        "        batch = batch.view(-1, D).to(device)\n",
        "        _, rec = loss(batch, *model)\n",
        "        rec = torch.sigmoid(rec)\n",
        "        rec = rec.view(-1, 28, 28).cpu().numpy()\n",
        "        batch = batch.view(-1, 28, 28).cpu().numpy()\n",
        "\n",
        "        fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(14, 7),\n",
        "                                 subplot_kw={'xticks': [], 'yticks': []})\n",
        "        for i in range(25):\n",
        "            if i % 5 == 0:\n",
        "                axes[i % 5, 2 * (i // 5)].set_title(\"Orig\")\n",
        "                axes[i % 5, 2 * (i // 5) + 1].set_title(\"Recon\")\n",
        "            axes[i % 5, 2 * (i // 5)].imshow(batch[i], cmap='gray')\n",
        "            axes[i % 5, 2 * (i // 5) + 1].imshow(rec[i], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn1cLF_BgAN2"
      },
      "outputs": [],
      "source": [
        "plot_reconstructions(loss_vae, [enc, dec])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
