
#UNIX
 #Useful directories
	/etc/systemd/system/							#Папка с описанием сервисов дл systemd
	/etc/nginx/sites-available/
	/etc/samba/
	/etc/ssh/sshd_config
	/etc/default/grub или /boot/cmdline.txt -> add "apparmor=1 lsm=lockdown,yama,apparmor"
 #General
	lsb_release -a 								#Узнать сборку системы
	lsblk									#Список подключеных устройств
	nvidia-smi								#Инфо по ресурсам видеокарты
	watch -n 0.5 nvidia-smi							#Инфо по ресурсам видеокарты с автобновлением
	sudo x-ui								#Команды настройки xray
	sudo journalctl -b || grep <name>					#Искать в журнале
	sudo dpkg -i <file>							#Установить из файла
	sudo netstat -ntlp							#Занятые порты
	ps aux | grep -i firefox 						#Поиск pid по имени
	sudo su 								#Смена пользователя на root 
	sudo passwd <user>							#сменить пароль
	sudo usermod -a -G <group> <user>					#добавить пользователя в группу
	scp user@11.22.33.44:/home/user/file ~/Downloads/			#Скопировать файлы с сервера на текущ комп
	autossh -N -R 2222:localhost:22 user@server				#Создать тунель с сервера 2222 на локалхост 22
	chmod 600 <file>
	sudo chown -R username:group directory
	sudo systemctl daemon-reload
	sudo systemctl enable <service>
	sudo systemctl start <service>
	ctrl+Z; bg								#Перевести процесс в фоновый режим
	fg									#Вернуть процесс из фона
	sudo journalctl -f							#Системный лог
	echo $(htpasswd -nB <user>) | sed -e s/\\$/\\$\\$/g                     #Зашифровать пароль
	python3 -m env .venv							#Создать .venv
	python3 -m pip install --upgrade pip
	pip install -r requirements.txt
	htpasswd -B registry.password <username>				#Создать логин-пароль в файл registry.password registry для
 #General python 
 	sudo add-apt-repository ppa:deadsnakes/ppa
 	sudo apt install python3.12
 	sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1
 	sudo update-alternatives --config python3
 #General server config
	apt update && apt upgrade -y						#Обновить сервер
	sudo nano /etc/ssh/sshd_config						#После добавления ssh ключа
		PasswordAuthentication no
		RootLogin no
	service ssh restart
 #Generate ssh key
	ssh-keygen -t rsa 							#На рабоче машине
	eval $(ssh-agent)
	ssh-add -k ~/.ssh/<private_key>						#Добавим ключ агенту
	ssh-copy-id username@remote_host					#Отправим на сервер
	cat ~/.ssh/<public_key> | ssh username@remote_host "cat >> ~/.ssh/authorized_keys"
	ssh -i ~/.ssh/<private_key> -o UserKnownHostsFile=~/.ssh/known_hosts  username@remote_host
	autossh -fnNT -L *:65000:127.0.0.1:65000 hetzner			#Создать тунель на сервер hetzner для всех подключающихся на порт 65000
 #Generate ssl certificate
	sudo snap install core; sudo snap refresh core
	sudo snap install --classic certbot
	sudo ln -s /snap/bin/certbot /usr/bin/certbot				#ссылка на файл
	sudo certbot --nginx
 #Wireguard
	apt install wireguard			
	echo "net.ipv4.ip_forward=1" >> /etc/sysctl.conf
	sysctl -p
	cd /etc/wireguard
	wg genkey | tee /etc/wireguard/privatekey | wg pubkey | tee /etc/wireguard/publickey
	chmod 600 privatekey
	nano wg0.conf
	#Server config
		[Interface]
		PrivateKey = <server_private_key>
		ListenPort = 51830
		PostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
		PostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE

		[Peer]
		PublicKey = <client_public_key>
		AllowedIps = 10.0.0.2/32
	systemctl enable wg-quick@wg0.service
	systemctl start wg-quick@wg0.service
	wg genkey | tee /etc/wireguard/<name>_privatekey | wg pubkey | tee /etc/wireguard/<name>_publickey
	nano client.conf
	#Client config
		[Interface]
		PrivateKey = <client_private_key>
		Address = 10.0.0.2/32
		DNS = 1.1.1.1, 8.8.8.8
		
		[Peer]
		PublicKey = <server_public_key>
		Endpoint = <ip>:51830
		AllowedIPs = 0.0.0.0/0, ::/0
		PersistentKeepalive = 20
	systemctl restart wg-quick@wg0.service
	
	sudo wg setconf wg0 wg_lenovo.conf
	sudo systemctl status wg-quick@wg_lenovo.service			#Управление из командной строки
	
 #UFW
	https://help.ubuntu.com/community/UFW
	
	sudo ufw status verbose
	sudo ufw allow 80
	sudo ufw deny 4000
	
 #TMUX
	https://losst.pro/shpargalka-po-tmux
	
	ctr+B default prefix -> nano .tmux.conf | set-option -g prefix C-a #Меняем префикс на ctr+A
	~/.tmux.conf.local							#Локальный конфиг
	tmux ls									#Список сессий
	tmux kill-server 
	tmux kill-session -t <name>
	tmux new-session -s <name> 						#Создать сессию
	tmux attach -t <name>							#Присоединиться
	ctr+A d									#Отсоединиться
	ctr+A c									#Новое окно
	ctr+A 0									#Перейти в 0 окно
	ctr+A "									#Разбить по горизонтали
	ctr+A %									#Разбить по вертикали
	ctr+A <-/ ->
	ctr+A o		 							#Навигация
	ctr+A , 								#Переименование окна
	ctr+A enter выделяем ctr+C q						#Копирование мышкой
	ctr+A [ выделить ctr+space, ctr+w для копирования			#Копируем
	ctr+A ]									#Вставляем

#DJANGO
 #General
	export PATH=$PATH:/home/<user>/.python/bin 				#Добавляем путь к питону
	python -m venv env							#Настраиваем виртуальное окружение
	source ./env/bin/activate	
	pip install -U pip
	pip install django
	pip freeze > requirements.txt
 #Project mngmt
	mkdir dj_project; cd dj_project
	django-admin startproject <project_name>				#Создание проекта ($django-admin получить лист команд)
	<project_name>/manage.py startapp <app_name>				#Создание приложения
	<project_name>/manage.py startserver 0.0.0.0:8000

	python manage.py makemigrations						#Создать снимок классов для сохранения в базу
	python manage.py migrate
	# Не забыть при первом старте проинициализировать БД: python manage.py makemigrations main 
	python manage.py sqlmigrate main 0001					#Для восстановления одной из миграций указать App, version
	python manage.py shell							#Использование питона для работы с объектами проекта
	python manage.py createsuperuser					#Создание админской учетки
	pip freeze > requiremints.txt						#Сохранить список необходимых пакетов
	
#FLASK
 #Project mngmt
 	$ export FLASK_APP=hello.py						#Указываем точку входа
	$ export FLASK_DEBUG=1							#Режим дебага
	$ export FLASK_ENV=development
	$ flask run								#Старт приложения
	$ flask db upgrade							#Обновить базы данных
	
	$ flask shell								#Добавление в базу через командную строку
	> from hello import User
	> user_john = User(username='john')
	> db.session.add_all([user_john])
	> db.session.commit()
	
	$ flask test								#Прогнать тесты
	$ docker exec -it <docker> bash > flask <command>			#Запустить команду внутри докера (если создать @app.cli.command)

#UNICORN
 #Settings for service
	[Unit]
	Description=gunicorn daemon
	After=network.target
	[Service]
	User=alexander
	Group=www-data
	WorkingDirectory=/home/alexander/django-site/src
	ExecStart=/home/alexander/django-site/env/bin/gunicorn 
		--workers 3 
		--bind unix:/home/alexander/django-site/gunicorn/gunicorn.sock config.wsgi:application 
		--access-logfile /home/alexander/django-site/gunicorn/access.log 
		--error-logfile /home/alexander/django-site/gunicorn/error.log
	Restart=on-failure
	[Install]
	WantedBy=multi-user.target
 #Set systemd
	sudo systemctl daemon-reload
	sudo systemctl start gunicorn
	sudo systemctl enable gunicorn

#NGINX
 #Useful links
	https://adamtheautomator.com/nginx-subdomain/
 #Site config
	sudo ln -s /etc/nginx/sites-available/site.conf /etc/nginx/sites-enabled/
	add to /etc/nginx/sites-available/site.conf :
	server {
		listen 80;
		server_name domain;

		location /static/ {
			root /home/alexander/django-site/static;
		}
		location / {
			include proxy_params;
			proxy_pass http://unix:/home/alexander/django-site/gunicorn/gunicorn.sock;
		}
	}
	server{
		listen 80;
		server_name www.domain;
		return 301 https://domain$request_uri;
	}
	sudo nginx -t
	sudo service nginx restart


#CLICKHOUSE
	config files: /etc/clickhouse-server/
	systemctl status clickhouse-server


#POSTGRES
	config files: /etc/postgresql/14/main/
	systemctl status postgresql
 #General
 	$ sudo -u postgres psql							#Переход в командную строку
 	$ psql -U <user> -d <database>						#Подключение к database за пользователя user
 	\q									#Выход из еомандной строки
 	\dt									#Список таблиц базы
 	\l
 	createuser --interactive
 	create user tester with password 'password';
	alter user tester superuser;
	
 	createdb <db_name>;
 	create database site_db;
	grant all privileges on database site_db to tester;

 	
#MONGODB
 #General
 	sudo docker exec -it mongo bash	
 	mongosh -> use admin -> db.createUser({user:'login',pwd:'pwd',roles:[{role:'readWrite',db:'db'}]})
 	mongosh -> use admin -> db.auth('login','pwd')
 	mongosh --u "login" --p "pwd" --authenticationDatabase "admin"
 	mongosh -> help
 	

#GIT
 #General
	git config --global user.name "Alexander"
	git config --global user.email "as.frantsev@gmail.com"
	git config pull.rebase true
	git config merge.tool vimdiff
	git config merge.conflictstyle diff3
	git config merge.prompt false
 #Имеем репозиторий
	git init
	git remote add origin git@github.com:<user>/<repository>.git
	git add .
	git commit -m 'initial commit'
	git push -u origin main
 #Копируем из 
	fit clone git@github.com:<user>/<repository>.git
	git rm <file_name>
	git tag -a <tag_name> -m '<description>' 				# тэгируем коммит
	git reflog 								# история изменений
	git show <commit_sha>							# посмотреть коммит
	git restore <file_name> (--staged)					# вернуть изменения (если уже в индексе)
	git reset --hard							# вернуть все изменения к глобальной версии
	git reset HEAD~1							# удалить последний комит
	git diff (--staged)							# сравнение с последним коммитом
	git diff branch1 branch2						# сравнить 2 ветки
	git checkout master							# переключение на ветку master
	git fetch branch1							# обновить инфо по ветке branch1 из глобального репо
	git merge branch1							# к текущей ветке примерджить ветку branch1
	git branch -d branch1							# удалить branch1
	git rebase
	git mergetool
	  ctr+w - переключение между окнами					
	  :diffg LO / BA / RE - какую ветку взять local / base / remote	
	  :wqa - выход с сохранением
 #Git-lfs
 	$ sudo apt install git-lfs
 	git lfs install
	git lfs track "*.pkl"
	git add .gitattributes
	git commit -m "update .gitattributes"
 #Стратегии ветвления
   #Git Flow
	Ключевая ветка main, develop рабочая ветка, от которой отпочковываются ветки feature и release
	После тестирования release она сливается в master. От master может создаваться hotfix
	Удобна: Надежная удобная система для редких релизов, можно поддерживать несколько версий.
	Неудобна: Для частого CI/CD, сложный merge крупных фичей
   #GitHub Flow
	Есть одна ветка main, от которой отпочковываются feature, 
	При сливании обновляем ветку из master, происходит тестирование, deploy pre-prod, мониторинг, слив в master
   #GitLab Flow
	Похоже на GitHub, но есть отдельная ветка production в которую сливают из master
 #Версионирование
	#SemVer
	breaking.feature.fix(major.minor.patch) breaking-несовместимость в изменениях, feature-совместимая функциональность
	#PEP440
	major.minor.micro
 #GitActions
 	sudo ./svc.sh install
 	sudo ./svc.sh start
 	sudo ./svc.sh status
 	
	
#DVC
	dvc init								#инициализация в проекте
	git commit -m "initialize dvc"						#коммит в git
	dvc remote add -d <name> <url_path>					#добавить удаленное хранилище
	dvc push / pull								#загрузить/скачать из удаленного репозитория
	dvc add data/<filename.csv>						#добавить файл в отслеживаемые
	dvc run -f <dvc_script_name>.dvc \
			-d <dependencie_name> \
			-o <output_name> \
			-m <metrics_file_name> \
			python <py_script_name>.py
	git checkout <tag>							#переключиться на гит
	dvc checkout 								#скачать файлы нужной ветки гита
	dvc repro								#воспроизвести пайплайн
	dvc dag 								#визуализация
	dvc metrics show							#показывает метрики (указанные в dvc.yaml)
	dvc plots show								#показывает графики (указанные в dvc.yaml)
	dvc params diff								#разница параметров (указанных в dvc.yaml)
	dvc metrics diff							#разница в метриках (указанных в dvc.yaml)
	dvc plots diff								#разница в графиках (указанных в dvc.yaml)
	dvc exp run
	dvc exp show

#DOCKER
	docker ps
	docker volume create <volume_name>
	docker volume prune							#Удалить неиспользуемые 
	docker network create <network_name>
	sudo curl -fsSL get.docker.com | sh					#установка
	sudo gpasswd -a $USER docker
	newgrp docker
	
	docker pull <cont_name>							#скачать образ
	docker images								#список доступных образов
	docker ps -a 								#список всех использованных котейнеров
	docker rm 0529d842a4 ff0a34kb						#удалет 2 контейнера по их ID
	docker rm $(docker ps -a -q -f status=exited) 				#удалет все завершенные контейнеры
	docker stop 0529d842a4							#остановка контейнера
	docker build --no-cache -t <name> .
	docker run -d -P -rm --name <friendly_name> <cont_name>
		-d (detached) в отдельном процессе
		-P открытые порты делает публичными
		-rm авто удаление после остановки
		-p 8888:80 перенаправление одного порта
		--name <friendly_name> присвоет имя для удобства
	docker port <friendly_name>						#список используемых портов
	docker exec -it <docker_name> bash					#зайти в командную строку контейнера
	  docker build -t image_name .
	  docker run -it image_name sh
	  ls -la
	docker logs <docker_name>						#логи контейнера
	docker commit $(docker ps -lq) my-image					#создать свой образ из последнего контейнера 
	docker tag my-image <ip-адрес сервера>:5000/my-image:latest		#добавить тег
	docker login <ip-адрес сервера>:5000					#логин к registry
	docker push <ip-адрес сервера>:5000/my-image:latest
	docker pull <ip-адрес сервера>:5000/my-image:latest
	docker compose up --no-deps --build <name>
	  docker compose -f <docker-compose.yml> up
	docker compose down --volumes --remove-orphans --rmi all


#Poetry
	poetry config virtualenvs.in-project
	poetry config virtualenvs.options.always-copy true
	poetry config virtualenvs.prefer-active-python true
	cat requirements.txt | xargs poetry add					#загрузить зависимости из requirements.txt
	poetry init								#инициализация нового проекта
	poetry env use <path_to_python>
	poetry install 								#установка зависимостей
	poetry update								#обновление зависимостей
	poetry show --tree 
	poetry show --latest
	poetry build								#собрать наш пакет
	poetry publish								#публикация на pypi
	poetry run python <file_name>
	poetry add (--dev) <package_name>					#установка пакета (только dev)
	poetry lock								#фиксация зависимостей для прода
	poetry export -f requirements.txt --without-hashes > requirements.txt	#Сохранение зависимостей в файл
	
	
#Home Assistant
  https://ihome.frantstech.site/hassio/system
  #Workaround with portainer
	sudo docker stop portainer
	sudo docker restart hassio_supervisor
	Update HA and then you can start portainer again (sudo docker start portainer)
  #Workaround 2
	ha jobs options --ignore-conditions healthy
